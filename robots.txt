# Robots.txt - WeBoat Brasil
# https://www.weboatbrasil.com.br

# Regra padrão para todos os crawlers
User-agent: *
Allow: /
Disallow: /templates/
Disallow: /docs/
Disallow: /*.md$

# Sitemap
Sitemap: https://www.weboatbrasil.com.br/sitemap.xml

# LLMs.txt (informações estruturadas para IA)
# https://www.weboatbrasil.com.br/llms.txt

# ============================================
# Crawlers de IA - Configuração GEO/SEO
# ============================================

# --- PERMITIR: Crawlers de busca/retrieval ---

# Bing (índice alimenta ChatGPT Search e Microsoft Copilot)
User-agent: Bingbot
Allow: /

# ChatGPT Search (aparecer nos resultados de busca da OpenAI)
User-agent: OAI-SearchBot
Allow: /

# ChatGPT navegação em tempo real (quando usuário pede para ler URL)
User-agent: ChatGPT-User
Allow: /

# Claude (Anthropic - busca e pesquisa)
User-agent: ClaudeBot
Allow: /
User-agent: Claude-SearchBot
Allow: /

# Perplexity
User-agent: PerplexityBot
Allow: /

# Google AI (Gemini, AI Overviews)
User-agent: Google-Extended
Allow: /

# Meta AI
User-agent: Meta-ExternalAgent
Allow: /

# --- BLOQUEAR: Crawlers de treinamento ---

# Treinamento OpenAI (bloquear uso para treinar modelos)
User-agent: GPTBot
Disallow: /

# Bytespider (TikTok/ByteDance - treinamento)
User-agent: Bytespider
Disallow: /
